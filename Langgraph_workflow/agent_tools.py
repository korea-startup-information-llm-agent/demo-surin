import os
import json
from datetime import datetime
from dotenv import load_dotenv
load_dotenv()

# ì›¹ ê²€ìƒ‰ ê´€ë ¨
from tavily import TavilyClient
from openai import OpenAI

# Qdrant ê´€ë ¨
from langchain_community.vectorstores import Qdrant
from qdrant_client import QdrantClient

# Huggingface embedding ëª¨ë¸ ê´€ë ¨
# from Langgraph_workflow.utils import *
from utils import *

# tool annotation
from langchain_core.tools import tool
from langchain_core.messages import SystemMessage

# ì„ë² ë”© ëª¨ë¸ ê´€ë ¨
from sentence_transformers import SentenceTransformer

# tavily_client ì„¤ì •
os.environ["TAVILY_API_KEY"] = os.getenv("TAVILY_API_KEY")
tavily_client = TavilyClient()

# í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI(
    api_key=os.getenv("UPSTAGE_API_KEY"),
    base_url="https://api.upstage.ai/v1"
)

# ì„ë² ë”© ëª¨ë¸ huggingface spaceë¡œ ë¶ˆëŸ¬ì™€ì„œ ì“°ê¸°
# EMBED_URL = os.getenv("EMBED_URL") + "/embed"

# embedding_function = HFSpaceEmbeddingFunction(EMBED_URL)

embedding_model = SentenceTransformer("dragonkue/BGE-m3-ko")

# qdrant DB ë¶ˆëŸ¬ì˜¤ê¸°
qdrant_client = QdrantClient(host="localhost", port=6333)

@tool("search_patent_db")
def search_patent_db(query: str) -> list:
    """Search the patent database for relevant information."""
    embed_query = embedding_model.encode([query])
    results = qdrant_client.search(
        collection_name="patent_db",
        query_vector=embed_query[0].tolist(),
        limit=5,
        score_threshold=0.05,
        with_payload=True,
        with_vectors=False,
    )
    return results

# í—¬í¼ í•¨ìˆ˜
def rewrite_query_for_search(query: str) -> str:
    """
    Use LLM to rewrite customer question into optimal search query.
    
    Args:
        query: Original search query
        
    Returns:
        LLM-optimized search query
    """
    try:
        # ì§€ê¸ˆ ì‹œê°„ì„ ë°˜ì˜í•˜ê¸° ìœ„í•œ ë°©ë²•
        current_time = datetime.now()
        current_date = current_time.strftime("%Y-%m-%d")
        
        rewrite_prompt = f"""
        <role>
        You are an expert search query optimizer. Your task is to transform verbose, conversational user questions into concise, keyword-driven search queries that will yield the best possible results from a web search engine.
        </role>

        <instructions>
        1.  **Identify Core Intent:** Analyze the user's question to understand their fundamental goal.
        2.  **Extract Key Entities:** Pull out essential keywords, names, locations, constraints (like budget or time), and concepts.
        3.  **Remove Filler:** Discard conversational fluff (e.g., "I was wondering", "can you help me", "please", "I think").
        4.  **Synthesize Keywords:** Combine the extracted entities into a logical, concise search string.
        5.  **Keep it Brief:** The final query should ideally be under 10 words.
        6.  **IMPORTANT:** Return ONLY the search query, no explanations, no tags, no thinking process.
        7.  **Time Context:** If user asks time-specific question, use current time information (current date: {current_date}).
        </instructions>

        <example>
        <user_question>
        I'm thinking of going to Europe this winter, maybe for like a week. I'm on a budget but I still want to see some cool historical stuff. Can you give me some recommendations?
        </user_question>
        <rewritten_query>
        best budget winter destinations Europe historical sites one week
        </rewritten_query>
        </example>

        <user_question>
        {query}
        </user_question>

        <output_format>
        Provide ONLY the rewritten search query as a single line of text. Do not add any introductory phrases like "Here is the query:".
        And also DO NOT PROVIDE THE THINKING STEPS, just provide the rewritten query.
        </output_format>

        <rewritten_query>
        """
        
        # êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ë½‘ì„ ìˆ˜ ìˆë„ë¡!
        response_format = {
            "type": "json_schema",
            "json_schema": {
                "name": "search_query_suggestions",
                "strict": True,
                "schema": {
                    "type": "object",
                    "properties": {
                        "rewritten_query": {
                            "type": "string",
                            "description": "The most relevant search query for this inquiry"
                        }
                    },
                    "required": ["rewritten_query"]
                }
            }
        }
    
        response = client.chat.completions.create(
            model="solar-pro2",
            messages=[{"role": "system", "content": rewrite_prompt}],
            # max_tokens=100,
            response_format=response_format
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # Return the primary query as the main result
        return result["rewritten_query"]
        
    except Exception as e:
        print(f"   âš ï¸ LLM query rewrite failed: {str(e)}, using original query")
        return query

# Web Search
@tool("search_in_web")
def search_in_web(query: str, rewrite_mode: bool = True) -> list:
    """Search the web for relevant information about a customer query.
    
    This tool searches the internet to find current information that can help
    answer customer questions, especially for technical issues or general topics
    not covered in the internal knowledge base.
    
    Args:
        query: The customer's question or search query
        max_results: Maximum number of search results to return (default: 3)
        rewrite_mode: Whether to use LLM to optimize the search query (default: True)
        
    Returns:
        List of dictionaries containing structured web search results with scores and metadata
    """
    try:
        search_query = query
        if rewrite_mode:
            search_query = rewrite_query_for_search(query)

        response = tavily_client.search(
            query=search_query,
            max_results=5,
            search_depth="advanced",
            include_answer=True,
            include_images=True,
        )

        results = []

        for result in response.get("results", []):
            score = result.get("score")
            if score and score > 0.5 :
                results.append({
                    "title": result.get("title", ''),
                    'url': result.get('url', ''),
                    'content': result.get('content', ''),
                    'score': score
                })

        return results

    except Exception as e:
        return [{"error": f"Web search error: {str(e)}"}]


# ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ê¸° ì²˜ë¦¬í•˜ê¸°
def _get_analysis_client_and_model():
    """
    Return (client, model) for analysis. Supports llama.cpp local models.
    Env:
      - USE_LOCAL_LLM: "1" or "true" to prefer local llama.cpp
      - LLAMA_MODEL_PATH: path to GGUF model file (e.g., "./models/qwen2.5-3b-instruct.gguf")
      - LLAMA_N_CTX: context window size (default: 2048)
      - LLAMA_N_THREADS: number of threads (default: 4)
      - UPSTAGE_API_KEY: used when local not enabled
    """
    global client

    use_local = os.getenv("USE_LOCAL_LLM", "").lower() in ("1", "true", "yes")
    
    if use_local and LLAMA_CPP_AVAILABLE:
        model_path = os.getenv("LLAMA_MODEL_PATH", "").strip()
        if not model_path:
            # ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œë“¤ ì‹œë„
            default_paths = [
                "./models/qwen2.5-3b-instruct.gguf",
                "./models/llama-3.2-3b-instruct.gguf", 
                "./models/phi-3-mini-4k-instruct.gguf",
                "./llama.cpp/models/qwen2.5-3b-instruct.gguf"
            ]
            for path in default_paths:
                if os.path.exists(path):
                    model_path = path
                    break
            
            if not model_path:
                print("âš ï¸ ë¡œì»¬ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í´ë¼ìš°ë“œ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                use_local = False
    
    if use_local and LLAMA_CPP_AVAILABLE and model_path:
        try:
            # llama.cpp í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            llama_client = Llama(
                model_path=model_path,
                n_ctx=int(os.getenv("LLAMA_N_CTX", "2048")),
                n_threads=int(os.getenv("LLAMA_N_THREADS", "4")),
                verbose=False
            )
            
            # OpenAI í˜¸í™˜ ë˜í¼ í´ë˜ìŠ¤
            class LlamaOpenAIWrapper:
                def __init__(self, llama_client):
                    self.llama_client = llama_client
                
                class ChatCompletion:
                    def __init__(self, llama_client):
                        self.llama_client = llama_client
                    
                    def create(self, model=None, messages=None, temperature=0.1, response_format=None, **kwargs):
                        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ ë¶„ë¦¬
                        system_msg = ""
                        user_msg = ""
                        
                        for msg in messages:
                            if msg["role"] == "system":
                                system_msg = msg["content"]
                            elif msg["role"] == "user":
                                user_msg = msg["content"]
                        
                        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                        if system_msg:
                            prompt = f"<|im_start|>system\n{system_msg}<|im_end|>\n<|im_start|>user\n{user_msg}<|im_end|>\n<|im_start|>assistant\n"
                        else:
                            prompt = f"<|im_start|>user\n{user_msg}<|im_end|>\n<|im_start|>assistant\n"
                        
                        # JSON ìŠ¤í‚¤ë§ˆê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì§€ì‹œì‚¬í•­ í¬í•¨
                        if response_format and "json_schema" in response_format:
                            prompt += "ì‘ë‹µì€ ë°˜ë“œì‹œ ì§€ì •ëœ JSON ìŠ¤í‚¤ë§ˆ í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n"
                        
                        # ëª¨ë¸ ì‹¤í–‰
                        response = self.llama_client(
                            prompt,
                            max_tokens=512,
                            temperature=temperature,
                            stop=["<|im_end|>", "\n\n"],
                            echo=False
                        )
                        
                        content = response["choices"][0]["text"].strip()
                        
                        # JSON ìŠ¤í‚¤ë§ˆ ì‘ë‹µì¸ ê²½ìš° íŒŒì‹± ì‹œë„
                        if response_format and "json_schema" in response_format:
                            try:
                                import json
                                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                                if "{" in content and "}" in content:
                                    start = content.find("{")
                                    end = content.rfind("}") + 1
                                    json_str = content[start:end]
                                    json.loads(json_str)  # ìœ íš¨ì„± ê²€ì‚¬
                                    content = json_str
                            except:
                                pass
                        
                        return type('Response', (), {
                            'choices': [type('Choice', (), {
                                'message': type('Message', (), {'content': content})()
                            })()]
                        })()
                
                def __init__(self, llama_client):
                    self.chat = self.ChatCompletion(llama_client)
            
            wrapper_client = LlamaOpenAIWrapper(llama_client)
            return wrapper_client, "llama-cpp-local"
            
        except Exception as e:
            print(f"âš ï¸ ë¡œì»¬ llama.cpp ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}, í´ë¼ìš°ë“œ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            use_local = False
    
    # ê¸°ë³¸ê°’: Upstage í´ë¼ìš°ë“œ ëª¨ë¸ ì‚¬ìš©
    if not use_local:
        model = os.getenv("ANALYSIS_MODEL", "solar-pro2")
        return client, model



# ì§ˆë¬¸ ë¶„ì„ tool
@tool("analyze_question")
def analyze_question(user_question: str) -> dict:
    """ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    extracted_info = {
        "ip_topic": None,                  # ì§ˆë¬¸ ì£¼ì œ (e.g., "íŠ¹í—ˆ ì¶œì›", "ìƒí‘œ ë“±ë¡", "ë””ìì¸ê¶Œ", "ì €ì‘ê¶Œ", "IP ì „ëµ")
        "is_about_patent": False,          # íŠ¹í—ˆ ê´€ë ¨ ì—¬ë¶€
        "is_about_trademark": False,       # ìƒí‘œ ê´€ë ¨ ì—¬ë¶€
        "is_about_copyright": False,       # ì €ì‘ê¶Œ ê´€ë ¨ ì—¬ë¶€
        "is_about_design": False,          # ë””ìì¸ê¶Œ ê´€ë ¨ ì—¬ë¶€

        "question_intent": None,           # ì˜ë„ (e.g., "ì¶œì› ì ˆì°¨ ë¬¸ì˜", "ì¶œì› ê°€ëŠ¥ì„± íŒë‹¨", "ë¹„ìš© ë¬¸ì˜", "ê¶Œë¦¬ ë³´í˜¸ ë²”ìœ„", "ì¹¨í•´ ì—¬ë¶€", "ê¸°ì¡´ íŠ¹í—ˆ ì¡°ì‚¬")
 # ì „ë¬¸ê°€ ìƒë‹´ì´ í•„ìš”í•œ ë³µì¡í•œ ì§ˆë¬¸ì¸ì§€
        "jurisdiction": None,             # êµ­ê°€/ê´€í•  êµ¬ì—­ (e.g., "ëŒ€í•œë¯¼êµ­", "ë¯¸êµ­", "PCT", "ìœ ëŸ½")

        "technology_field": None,         # ê¸°ìˆ  ë¶„ì•¼ (e.g., "AI", "í—¬ìŠ¤ì¼€ì–´", "í•€í…Œí¬", "í™”ì¥í’ˆ")
        "has_existing_product": False,    # ê¸°ì¡´ ì œí’ˆì´ë‚˜ ì•„ì´ë””ì–´ê°€ ìˆëŠ”ì§€ ì—¬ë¶€
        "product_description": None,      # ì•„ì´ë””ì–´/ì œí’ˆ ì„¤ëª… ìš”ì•½
        "is_confidential": None,          # ê¸°ë°€ ì •ë³´ í¬í•¨ ì—¬ë¶€ (ë³´ì•ˆ í•„ìš” ì‹œ í‘œì‹œ)

        "needs_clarification": False,     # ì§ˆë¬¸ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ë³´ì™„ ì„¤ëª… í•„ìš”í•œì§€
        "clarification_question": None    # ëª…í™•íˆ í•˜ê¸° ìœ„í•œ ì§ˆë¬¸
    }

    text = user_question.lower()

    # 1) ë£° ë² ì´ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    topic_keywords = {
        "patent": ["íŠ¹í—ˆ", "ì¶œì›", "ëª…ì„¸ì„œ", "ì„ í–‰ê¸°ìˆ ", "pct", "ìš°ì„ ê¶Œ ì£¼ì¥", "ë°œëª…"],
        "trademark": ["ìƒí‘œ", "ë¸Œëœë“œ", "ë¡œê³ ", "ì„œë¹„ìŠ¤í‘œ", "ì¶œì›ë²ˆí˜¸", "ë“±ë¡ë²ˆí˜¸"],
        "copyright": ["ì €ì‘ê¶Œ", "ì €ì‘ë¬¼", "ì €ì‘ìì˜", "ë¼ì´ì„ ìŠ¤", "license", "ì €ì‘"],
        "design": ["ë””ìì¸ê¶Œ", "ì˜ì¥", "ë„ì•ˆ", "ë””ìì¸ ë“±ë¡"],
    }
    intent_map = {
        "procedure": ["ì ˆì°¨", "ë°©ë²•", "ì–´ë–»ê²Œ", "ê³¼ì •", "flow"],
        "feasibility": ["ê°€ëŠ¥ì„±", "ë ê¹Œìš”", "ë ê¹Œ", "ìš”ê±´", "ì¶©ì¡±"],
        "cost": ["ë¹„ìš©", "ìˆ˜ìˆ˜ë£Œ", "ê²¬ì ", "ê°€ê²©"],
        "scope": ["ë²”ìœ„", "ê¶Œë¦¬ë²”ìœ„", "í•´ì„", "ì²­êµ¬í•­"],
        "infringement": ["ì¹¨í•´", "ë¶„ìŸ", "ì†Œì†¡", "ê²½ê³ ì¥"],
        "search": ["ì¡°ì‚¬", "ê²€ìƒ‰", "ì„ í–‰ê¸°ìˆ ", "prior art", "ì¡°íšŒ"],
    }
    jurisdiction_map = {
        "ëŒ€í•œë¯¼êµ­": ["í•œêµ­", "ëŒ€í•œë¯¼êµ­", "kipo", "íŠ¹í—ˆì²­"],
        "í•´ì™¸": ["í•´ì™¸", "ì™¸êµ­"],
        # "ë¯¸êµ­": ["ë¯¸êµ­", "us", "uspto"],
        # "ìœ ëŸ½": ["ìœ ëŸ½", "euipo", "epo", "ìœ ëŸ½íŠ¹í—ˆ"],
        # "pct": ["pct", "êµ­ì œì¶œì›"],
        # "ì¤‘êµ­": ["ì¤‘êµ­", "cnipa"],
        # "ì¼ë³¸": ["ì¼ë³¸", "jpo"],
    }
    tech_map = {
        "ict-sw": ["ë¹…ë°ì´í„°â€¢ì¸ê³µì§€ëŠ¥", "ì»´í“¨íŒ…â€¢ì†Œí”„íŠ¸ì›¨ì–´"],
    }

    # Topic flags
    if any(topic_keyword in text for topic_keyword in topic_keywords["patent"]):
        extracted_info["is_about_patent"] = True
        if not extracted_info["ip_topic"]:
            extracted_info["ip_topic"] = "íŠ¹í—ˆ"

    if any(topic_keyword in text for topic_keyword in topic_keywords["trademark"]):
        extracted_info["is_about_trademark"] = True
        if not extracted_info["ip_topic"]:
            extracted_info["ip_topic"] = "ìƒí‘œ"

    if any(topic_keyword in text for topic_keyword in topic_keywords["copyright"]):
        extracted_info["is_about_copyright"] = True
        if not extracted_info["ip_topic"]:
            extracted_info["ip_topic"] = "ì €ì‘ê¶Œ"

    if any(topic_keyword in text for topic_keyword in topic_keywords["design"]):
        extracted_info["is_about_design"] = True
        if not extracted_info["ip_topic"]:
            extracted_info["ip_topic"] = "ë””ìì¸ê¶Œ"

    # Intent
    for intent, words in intent_map.items():
        if any(word in text for word in words):
            extracted_info["question_intent"] = {
                "procedure": "ì¶œì› ì ˆì°¨ ë¬¸ì˜",
                "feasibility": "ì¶œì› ê°€ëŠ¥ì„± íŒë‹¨",
                "cost": "ë¹„ìš© ë¬¸ì˜",
                "scope": "ê¶Œë¦¬ ë³´í˜¸ ë²”ìœ„",
                "infringement": "ì¹¨í•´ ì—¬ë¶€",
                "search": "ê¸°ì¡´ íŠ¹í—ˆ ì¡°ì‚¬",
            }[intent]
            break

    # Jurisdiction
    for name, words in jurisdiction_map.items():
        if any(word in text for word in words):
            extracted_info["jurisdiction"] = name
            break

    # Technology field
    for name, words in tech_map.items():
        if any(word in text for word in words):
            extracted_info["technology_field"] = name
            break

    # Existing product and description heuristics
    has_product_phrases = ["ì œí’ˆ", "ì„œë¹„ìŠ¤", "ì•±", "ì¥ì¹˜", "ë””ë°”ì´ìŠ¤", "ì•„ì´ë””ì–´", "í”„ë¡œí† íƒ€ì…", "ê¸°ëŠ¥"]
    extracted_info["has_existing_product"] = any(word in text for word in has_product_phrases)

    # crude short description snippet
    if extracted_info["has_existing_product"]:
        # pick a short window as a naive description
        extracted_info["product_description"] = user_question.strip()[:200]

    # Confidentiality signals
    if any(word in text for word in ["ë¹„ë°€", "ë‚´ë¶€", "ê³µê°œí•˜ì§€", "nda", "ê¸°ë°€"]):
        extracted_info["is_confidential"] = True

    # Clarification need
    too_short = len(user_question.strip()) < 15
    no_topic = not any([extracted_info["is_about_patent"], extracted_info["is_about_trademark"],
                        extracted_info["is_about_copyright"], extracted_info["is_about_design"]])

    no_intent = extracted_info["question_intent"] is None

    extracted_info["needs_clarification"] = too_short or (no_topic and no_intent)

    if extracted_info["needs_clarification"]:
        extracted_info["clarification_question"] = "ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”? (ì£¼ì œ, êµ­ê°€, ëª©ì , ì œí’ˆ/ì•„ì´ë””ì–´ ì—¬ë¶€ ë“±)"

    
    return extracted_info




# ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ê¸° ì²˜ë¦¬í•˜ê¸°
def classify_question_node(state: dict) -> dict:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì˜ ê¸°ë³¸ ìœ í˜•ì„ ë¶„ë¥˜í•˜ëŠ” ë…¸ë“œ
    """
    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸°
    user_messages = [msg for msg in state["messages"] if hasattr(msg, 'content') and msg.__class__.__name__ == 'HumanMessage']
    if not user_messages:
        return state
    
    user_message = user_messages[-1].content
    
    # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
    prompt = f"""
    You are a startup knowledge assistant that classifies user questions into one of several types.

    Choose ONE of the following `question_type` values based on the user input:
    - summary: ìš”ì•½ì´ë‚˜ ê°œìš”ë¥¼ ìš”ì²­í•˜ëŠ” ì§ˆë¬¸
    - inmemory: ê¸°ì–µëœ ì •ë³´ë‚˜ í•™ìŠµëœ ì§€ì‹ì„ ìš”ì²­í•˜ëŠ” ì§ˆë¬¸
    - outmemory: ì™¸ë¶€ ê²€ìƒ‰ì´ë‚˜ ìµœì‹  ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸
    - clarification: ëª…í™•í™”ë‚˜ ì¶”ê°€ ì„¤ëª…ì´ í•„ìš”í•œ ì§ˆë¬¸
    - generation: ìƒˆë¡œìš´ ë‚´ìš© ìƒì„±ì´ë‚˜ ì°½ì‘ì„ ìš”ì²­í•˜ëŠ” ì§ˆë¬¸
    - intent_classification: ì˜ë„ë‚˜ ëª©ì ì„ íŒŒì•…í•˜ë ¤ëŠ” ì§ˆë¬¸

    Only return the type as a single lowercase word with no explanation.

    [USER]
    {user_message}
    [/USER]
    [TAG]
    """

    try:
        ai_client, model = _get_analysis_client_and_model()
        response = ai_client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )

        question_type = response.choices[0].message.content.strip().lower()
        
    except Exception as e:
        print(f"âš ï¸ ì§ˆë¬¸ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}, ê¸°ë³¸ê°’ ì‚¬ìš©")
        question_type = "clarification"

    # question_analysisì— ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼ë§Œ ì €ì¥
    current_analysis = state.get("question_analysis", {})
    updated_analysis = {
        **current_analysis,
        "question_type": question_type
    }

    # ë¶„ë¥˜ ê²°ê³¼ë¥¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì¶”ê°€í•´ì„œ LLMì´ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.
    classification_message = SystemMessage(
        content=f"""
        [ì§ˆë¬¸ ë¶„ë¥˜ ê²°ê³¼]
        ì§ˆë¬¸ ìœ í˜•: {question_type}

        ì´ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ TOOLì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
        - analyze_question: ì§ˆë¬¸ì„ ìƒì„¸ ë¶„ì„í•˜ì—¬ IP ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        - search_ipraw: ì§€ì‹ì¬ì‚°ê¶Œë²• ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìƒí‘œ, ì €ì‘ê¶Œ, ë””ìì¸ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        - search_patent: íŠ¹í—ˆ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ íŠ¹í—ˆ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        - search_in_web: ì›¹ì—ì„œ ìµœì‹  ì •ë³´ì™€ ì¼ë°˜ì ì¸ ì§€ì‹ì¬ì‚°ê¶Œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:
        - outmemory: ì›¹ ê²€ìƒ‰ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš©
        - clarification: ëª…í™•í™” ì§ˆë¬¸ ìƒì„±
        - summary: ê¸°ì¡´ ì§€ì‹ìœ¼ë¡œ ìš”ì•½ ì œê³µ
        - generation: ì°½ì˜ì ì¸ ë‹µë³€ ìƒì„±
        """
    )

    return {
        **state,
        "question_analysis": updated_analysis,
        "messages": state["messages"] + [classification_message]
    }




# ------------------------------------------------------------------------------- #

# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ìˆ˜ì •ëœ ë²„ì „)
def test_search_functions():
    """ìˆ˜ì •ëœ ê²€ìƒ‰ í•¨ìˆ˜ë“¤ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\nğŸ” ê²€ìƒ‰ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    test_queries = [
        "íŠ¹í—ˆ ì¶œì› ì ˆì°¨",
        "ìƒí‘œ ë“±ë¡ ë°©ë²•", 
        "ì§€ì‹ì¬ì‚°ê¶Œ ë³´í˜¸",
        "ë¹…ë°ì´í„° ì¸ê³µì§€ëŠ¥",
        "ë¨¸ì‹ ëŸ¬ë‹ ê¸°ìˆ "
    ]
    
    for query in test_queries:
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
        
        # IP ë²•ë ¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("   ğŸ“š IP ë²•ë ¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        try:
            ipraw_results = search_ipraw(query)
            print(f"   ğŸ“Š ê²°ê³¼: {len(ipraw_results)}ê°œ")
            for i, result in enumerate(ipraw_results[:2]):  # ìƒìœ„ 2ê°œë§Œ í‘œì‹œ
                if "error" in result:
                    print(f"     âŒ ì˜¤ë¥˜: {result['error']}")
                else:
                    content = result.get("content", "")
                    print(f"     âœ… ê²°ê³¼ {i+1}: {content[:150]}...")
        except Exception as e:
            print(f"   âŒ IP ë²•ë ¹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        
        # íŠ¹í—ˆ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("   ğŸ“„ íŠ¹í—ˆ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        try:
            patent_results = search_patent(query)
            print(f"   ğŸ“Š ê²°ê³¼: {len(patent_results)}ê°œ")
            for i, result in enumerate(patent_results[:2]):  # ìƒìœ„ 2ê°œë§Œ í‘œì‹œ
                if "error" in result:
                    print(f"     âŒ ì˜¤ë¥˜: {result['error']}")
                else:
                    content = result.get("content", "")
                    print(f"     âœ… ê²°ê³¼ {i+1}: {content[:150]}...")
        except Exception as e:
            print(f"   âŒ íŠ¹í—ˆ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        
        print("   " + "="*50)
    
    print("\nâœ… ê²€ìƒ‰ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

# ë²¡í„° DB ì§ì ‘ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
def test_direct_vector_search():
    """ë²¡í„° DBë¥¼ ì§ì ‘ ê²€ìƒ‰í•´ì„œ ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    print("\nğŸ” ë²¡í„° DB ì§ì ‘ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸...")
    
    test_queries = [
        "ë¹…ë°ì´í„°",
        "ì¸ê³µì§€ëŠ¥", 
        "ë¨¸ì‹ ëŸ¬ë‹",
        "íŠ¹í—ˆ ì¶œì›"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
        
        # IP ë²•ë ¹ DB ì§ì ‘ ê²€ìƒ‰
        print("   ğŸ“š IP ë²•ë ¹ DB ì§ì ‘ ê²€ìƒ‰:")
        try:
            if ipraw_retriever:
                docs = ipraw_retriever.invoke(query)
                print(f"   ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ ë¬¸ì„œ")
                
                for i, doc in enumerate(docs[:2]):  # ìƒìœ„ 2ê°œë§Œ í‘œì‹œ
                    print(f"\n     ğŸ“„ ë¬¸ì„œ {i+1}:")
                    print(f"       page_content: {doc.page_content[:100] if doc.page_content else 'None'}...")
                    print(f"       metadata: {doc.metadata}")
                    
                    # metadataì—ì„œ ì‹¤ì œ ë‚´ìš© ì°¾ê¸°
                    if not doc.page_content:
                        metadata = doc.metadata
                        for key in ['content', 'text', 'claims', 'title']:
                            if key in metadata and metadata[key]:
                                print(f"       ì‹¤ì œ ë‚´ìš©({key}): {str(metadata[key])[:100]}...")
                                break
            else:
                print("   âŒ IP ë²•ë ¹ retrieverê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"   âŒ IP ë²•ë ¹ DB ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        
        # íŠ¹í—ˆ DB ì§ì ‘ ê²€ìƒ‰
        print("   ğŸ“„ íŠ¹í—ˆ DB ì§ì ‘ ê²€ìƒ‰:")
        try:
            if patent_retriever:
                docs = patent_retriever.invoke(query)
                print(f"   ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ ë¬¸ì„œ")
                
                for i, doc in enumerate(docs[:2]):  # ìƒìœ„ 2ê°œë§Œ í‘œì‹œ
                    print(f"\n     ğŸ“„ ë¬¸ì„œ {i+1}:")
                    print(f"       page_content: {doc.page_content[:100] if doc.page_content else 'None'}...")
                    print(f"       metadata: {doc.metadata}")
                    
                    # metadataì—ì„œ ì‹¤ì œ ë‚´ìš© ì°¾ê¸°
                    if not doc.page_content:
                        metadata = doc.metadata
                        for key in ['content', 'text', 'claims', 'title']:
                            if key in metadata and metadata[key]:
                                print(f"       ì‹¤ì œ ë‚´ìš©({key}): {str(metadata[key])[:100]}...")
                                break
            else:
                print("   âŒ íŠ¹í—ˆ retrieverê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"   âŒ íŠ¹í—ˆ DB ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        
        print("   " + "="*50)
    
    print("\nâœ… ë²¡í„° DB ì§ì ‘ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

# ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
def test_web_search():
    """ì›¹ ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\nğŸ” ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    test_queries = [
        "íŠ¹í—ˆ ì¶œì› ì ˆì°¨ 2024",
        "ìƒí‘œ ë“±ë¡ ë¹„ìš©",
        "ì§€ì‹ì¬ì‚°ê¶Œ ë³´í˜¸ ë°©ë²•"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
        
        try:
            web_results = search_in_web(query, rewrite_mode=True)
            print(f"   ğŸ“Š ì›¹ ê²€ìƒ‰ ê²°ê³¼: {len(web_results)}ê°œ")
            
            for i, result in enumerate(web_results[:2]):  # ìƒìœ„ 2ê°œë§Œ í‘œì‹œ
                if "error" in result:
                    print(f"     âŒ ì˜¤ë¥˜: {result['error']}")
                else:
                    title = result.get("title", "")
                    content = result.get("content", "")
                    score = result.get("score", 0)
                    print(f"     âœ… ê²°ê³¼ {i+1}: {title}")
                    print(f"        ì ìˆ˜: {score}")
                    print(f"        ë‚´ìš©: {content[:100]}...")
        except Exception as e:
            print(f"   âŒ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        
        print("   " + "="*50)
    
    print("\nâœ… ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

# ì¢…í•© í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def run_all_tests():
    """ëª¨ë“  ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("ğŸš€ StartMate RAG ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # 1. ë²¡í„° DB ë°ì´í„° êµ¬ì¡° í™•ì¸
    # print("\n1ï¸âƒ£ ë²¡í„° DB ë°ì´í„° êµ¬ì¡° í™•ì¸")
    # diagnose_vector_db_structure()
    
    # 2. ë²¡í„° DB ì§ì ‘ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ ë²¡í„° DB ì§ì ‘ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    test_direct_vector_search()
    
    # 3. ìˆ˜ì •ëœ ê²€ìƒ‰ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ ìˆ˜ì •ëœ ê²€ìƒ‰ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
    test_search_functions()
    
    # 4. ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n4ï¸âƒ£ ì›¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    test_web_search()
    
    print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("\nğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
    print("   - ë²¡í„° DB ë°ì´í„° êµ¬ì¡° í™•ì¸ ì™„ë£Œ")
    print("   - ì§ì ‘ ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì œ ë°ì´í„° í™•ì¸ ì™„ë£Œ")
    print("   - ìˆ˜ì •ëœ ê²€ìƒ‰ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("   - ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

# ëª¨ë“ˆ ë¡œë“œ ì‹œ ìë™ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    run_all_tests()

    